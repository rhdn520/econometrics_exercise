{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('lendingclub_train.dta')\n",
    "# df.head()\n",
    "# df.describe()\n",
    "columns_to_drop = [\n",
    "    \"index\",\n",
    "    \"depvar\",\n",
    "    \"total_acc\", \n",
    "    \"out_prncp\", \n",
    "    \"out_prncp_inv\", \n",
    "    \"total_pymnt\", \n",
    "    \"total_pymnt_inv\", \n",
    "    \"total_rec_prncp\", \n",
    "    \"total_rec_int\", \n",
    "    \"total_rec_late_fee\", \n",
    "    \"recoveries\", \n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\", \n",
    "    \"last_fico_range_high\", \n",
    "    \"last_fico_range_low\", \n",
    "    \"tot_coll_amt\", \n",
    "    \"tot_cur_bal\", \n",
    "    \"initial_list_status1\", \n",
    "    \"initial_list_status2\", \n",
    "    \"elapsed_t\",\n",
    "    \"purpose1\",\n",
    "    \"addr_state1\",\n",
    "    \"elapsed_t\",\n",
    "    \"debt_settlement_flag1\",\n",
    "    \"term1\",\n",
    "    \"mths_since_last_delinq1\",\n",
    "    \"mths_since_last_major_derog1\",\n",
    "    \"mths_since_last_record1\",\n",
    "    \"mths_since_rcnt_il1\",\n",
    "    \"mths_since_recent_bc1\",\n",
    "    \"mths_since_recent_bc_dlq1\",\n",
    "    \"mths_since_recent_inq1\",\n",
    "    \"mths_since_recent_revol_delinq1\"\n",
    "]\n",
    "\n",
    "issue_d_count = 1\n",
    "while(issue_d_count <= 118):\n",
    "    word_tmp = \"issue_d\" + str(issue_d_count)\n",
    "    columns_to_drop.append(word_tmp)\n",
    "    issue_d_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling Logic\n",
    "Undersampling을 안할거면 다음 로직 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df['depvar'] == 0]\n",
    "df_minority = df[df['depvar'] == 1]\n",
    "\n",
    "# Count number of instances in the minority class\n",
    "minority_count = len(df_minority)\n",
    "\n",
    "# Undersample the majority class\n",
    "df_majority_undersampled = df_majority.sample(n=minority_count, random_state=42)\n",
    "\n",
    "# Combine minority class with the undersampled majority class\n",
    "df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_undersampled = df_undersampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# Now split into features and target, and then into training and testing sets\n",
    "y = df_undersampled['depvar']\n",
    "X = df_undersampled.drop(columns=columns_to_drop)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "# X.info(verbose=True,max_cols=None)\n",
    "# y.head()\n",
    "# X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['depvar']\n",
    "# X = df.drop(columns=columns_to_drop)\n",
    "# # X = df.drop(columns=['depvar','index'])\n",
    "\n",
    "# X.info(verbose=True,max_cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.5353166460990906\n",
      "\n",
      "Best val_accuracy So Far: 0.5621548295021057\n",
      "Total elapsed time: 00h 03m 18s\n",
      "1772/1772 [==============================] - 1s 457us/step - loss: 0.7056 - accuracy: 0.5622\n",
      "Test Accuracy: 0.56, Test Loss: 0.71\n",
      "Best hyperparameters saved to 'best_hyperparameters.json'\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights for the tuning subset\n",
    "# class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=16, max_value=512, step=16), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('units2', min_value=16, max_value=512, step=16), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout2', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Single output neuron\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                  loss='binary_crossentropy',  # Binary crossentropy loss\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='hyperband',\n",
    "    project_name='hyperband_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    epochs=10, validation_data=(X_val, y_val), batch_size = 256\n",
    "    # , class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_val, y_val)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}, Test Loss: {loss:.2f}\")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Prepare the best hyperparameters for saving\n",
    "best_hyperparameters = {\n",
    "    'units': best_hps.get('units'),\n",
    "    'units2': best_hps.get('units2'),\n",
    "    'dropout': best_hps.get('dropout'),\n",
    "    'dropout2': best_hps.get('dropout2'),\n",
    "    'learning_rate': best_hps.get('learning_rate')\n",
    "}\n",
    "\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_hyperparameters, f)\n",
    "\n",
    "print(\"Best hyperparameters saved to 'best_hyperparameters.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 40.9154 - accuracy: 0.5083\n",
      "Epoch 2/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5253\n",
      "Epoch 3/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6928 - accuracy: 0.5127\n",
      "Epoch 4/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.7743 - accuracy: 0.5028\n",
      "Epoch 5/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6969 - accuracy: 0.4986\n",
      "Epoch 6/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.9179 - accuracy: 0.4997\n",
      "Epoch 7/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6945 - accuracy: 0.4987\n",
      "Epoch 8/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 9/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 10/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 11/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 12/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 13/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4982\n",
      "Epoch 14/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 15/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 16/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 17/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 18/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 19/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 20/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 22/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 24/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 25/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 26/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 27/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 28/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 29/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4973\n",
      "Epoch 30/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 31/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 32/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4983\n",
      "Epoch 33/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 34/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 35/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 36/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 37/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 38/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 39/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 41/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 42/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 43/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 44/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 45/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 46/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 47/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 48/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 49/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 50/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 51/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 52/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 53/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 54/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 55/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4979\n",
      "Epoch 56/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4982\n",
      "Epoch 57/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 58/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 59/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 60/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4982\n",
      "Epoch 61/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 62/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 63/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 64/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 65/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 66/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4981\n",
      "Epoch 67/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 70/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 71/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 72/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 73/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 74/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 76/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 77/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 78/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 79/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 80/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 82/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 83/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 84/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 85/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 86/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 87/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 88/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 89/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 90/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 91/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 92/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 93/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5011\n",
      "Epoch 94/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 95/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 96/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 97/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 98/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 99/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 100/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 101/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 102/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 103/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 104/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 105/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 106/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 107/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 108/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 109/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 110/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6931 - accuracy: 0.5011\n",
      "Epoch 111/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 112/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 113/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 114/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 115/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 116/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 117/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 118/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 119/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 120/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 121/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 122/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 123/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 124/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6931 - accuracy: 0.5009\n",
      "Epoch 125/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 126/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 127/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 128/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6931 - accuracy: 0.5010\n",
      "Epoch 129/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 130/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4981\n",
      "Epoch 131/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6931 - accuracy: 0.5016\n",
      "Epoch 132/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 133/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5011\n",
      "Epoch 134/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 136/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 137/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 138/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 139/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 140/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 141/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4978\n",
      "Epoch 142/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 143/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 144/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4976\n",
      "Epoch 145/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 146/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4981\n",
      "Epoch 147/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 149/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 150/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 151/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 152/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 153/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4976\n",
      "Epoch 154/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 155/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 156/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 158/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 159/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 160/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 161/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 162/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 163/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 164/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 165/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 166/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 167/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 168/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 169/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 170/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 171/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 172/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4983\n",
      "Epoch 173/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 174/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5015\n",
      "Epoch 175/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 176/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 177/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 178/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 179/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 180/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5007\n",
      "Epoch 181/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 182/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 183/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 184/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 185/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 186/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 187/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 188/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 189/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 190/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4981\n",
      "Epoch 191/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 192/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 193/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 194/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 195/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4979\n",
      "Epoch 196/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 197/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 198/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 199/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 200/200\n",
      "1107/1107 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choeseung-u/programming/econometrics/econometrics/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Class Weight\n",
    "# class_weights = compute_class_weight('balanced', classes=[0,1], y=y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "# Load best hyperparameters\n",
    "with open('best_hyperparameters.json') as f:\n",
    "    best_hps = json.load(f)\n",
    "\n",
    "model_path = 'final_trained_model.h5'\n",
    "if(os.path.exists(model_path)):\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=best_hps['units'], activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(best_hps['dropout']))\n",
    "    model.add(Dense(units=best_hps['units2'], activation='relu'))\n",
    "    model.add(Dropout(best_hps['dropout2']))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=200, batch_size=256\n",
    "                    # , class_weight=class_weight_dict\n",
    "                    )  # Adjust epochs and batch_size as needed\n",
    "\n",
    "# Save the final trained model\n",
    "model.save('final_trained_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1772/1772 - 1s - loss: 0.6931 - accuracy: 0.5013 - 895ms/epoch - 505us/step\n",
      "Test accuracy: 0.5013056993484497\n",
      "1772/1772 [==============================] - 1s 443us/step\n",
      "Confusion Matrix:\n",
      " [[    0 28263]\n",
      " [    0 28411]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     28263\n",
      "         1.0       0.50      1.00      0.67     28411\n",
      "\n",
      "    accuracy                           0.50     56674\n",
      "   macro avg       0.25      0.50      0.33     56674\n",
      "weighted avg       0.25      0.50      0.33     56674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choeseung-u/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/choeseung-u/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/choeseung-u/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plotting the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Predictions for confusion matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int).reshape(-1)  # Adjust this line if not a binary classification\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
