{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('lendingclub_train.dta')\n",
    "# df.head()\n",
    "# df.describe()\n",
    "columns_to_drop = [\n",
    "    \"index\",\n",
    "    \"depvar\",\n",
    "    \"total_acc\", \n",
    "    \"out_prncp\", \n",
    "    \"out_prncp_inv\", \n",
    "    \"total_pymnt\", \n",
    "    \"total_pymnt_inv\", \n",
    "    \"total_rec_prncp\", \n",
    "    \"total_rec_int\", \n",
    "    \"total_rec_late_fee\", \n",
    "    \"recoveries\", \n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\", \n",
    "    \"last_fico_range_high\", \n",
    "    \"last_fico_range_low\", \n",
    "    \"tot_coll_amt\", \n",
    "    \"tot_cur_bal\", \n",
    "    \"initial_list_status1\", \n",
    "    \"initial_list_status2\", \n",
    "    \"elapsed_t\",\n",
    "    \"purpose1\",\n",
    "    \"addr_state1\",\n",
    "    \"elapsed_t\",\n",
    "    \"debt_settlement_flag1\",\n",
    "    \"term1\",\n",
    "    \"mths_since_last_delinq1\",\n",
    "    \"mths_since_last_major_derog1\",\n",
    "    \"mths_since_last_record1\",\n",
    "    \"mths_since_rcnt_il1\",\n",
    "    \"mths_since_recent_bc1\",\n",
    "    \"mths_since_recent_bc_dlq1\",\n",
    "    \"mths_since_recent_inq1\",\n",
    "    \"mths_since_recent_revol_delinq1\"\n",
    "]\n",
    "\n",
    "issue_d_count = 1\n",
    "while(issue_d_count <= 118):\n",
    "    word_tmp = \"issue_d\" + str(issue_d_count)\n",
    "    columns_to_drop.append(word_tmp)\n",
    "    issue_d_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling Logic\n",
    "Undersampling을 안할거면 다음 로직 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df['depvar'] == 0]\n",
    "df_minority = df[df['depvar'] == 1]\n",
    "\n",
    "# Count number of instances in the minority class\n",
    "minority_count = len(df_minority)\n",
    "\n",
    "# Undersample the majority class\n",
    "df_majority_undersampled = df_majority.sample(n=minority_count, random_state=42)\n",
    "\n",
    "# Combine minority class with the undersampled majority class\n",
    "df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_undersampled = df_undersampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# Now split into features and target, and then into training and testing sets\n",
    "y = df_undersampled['depvar']\n",
    "X = df_undersampled.drop(columns=columns_to_drop)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "# X.info(verbose=True,max_cols=None)\n",
    "# y.head()\n",
    "# X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['depvar']\n",
    "# X = df.drop(columns=columns_to_drop)\n",
    "# # X = df.drop(columns=['depvar','index'])\n",
    "\n",
    "# X.info(verbose=True,max_cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.5082843899726868\n",
      "\n",
      "Best val_accuracy So Far: 0.7466694712638855\n",
      "Total elapsed time: 00h 02m 48s\n",
      "1772/1772 [==============================] - 1s 481us/step - loss: 1.4991 - accuracy: 0.7467\n",
      "Test Accuracy: 0.75, Test Loss: 1.50\n",
      "Best hyperparameters saved to 'best_hyperparameters.json'\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights for the tuning subset\n",
    "# class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=16, max_value=512, step=16), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('units2', min_value=16, max_value=512, step=16), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout2', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Single output neuron\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                  loss='binary_crossentropy',  # Binary crossentropy loss\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='hyperband',\n",
    "    project_name='hyperband_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    epochs=10, validation_data=(X_val, y_val), batch_size = 256\n",
    "    # , class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_val, y_val)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}, Test Loss: {loss:.2f}\")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Prepare the best hyperparameters for saving\n",
    "best_hyperparameters = {\n",
    "    'units': best_hps.get('units'),\n",
    "    'units2': best_hps.get('units2'),\n",
    "    'dropout': best_hps.get('dropout'),\n",
    "    'dropout2': best_hps.get('dropout2'),\n",
    "    'learning_rate': best_hps.get('learning_rate')\n",
    "}\n",
    "\n",
    "# Save the best hyperparameters to a JSON file\n",
    "with open('best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_hyperparameters, f)\n",
    "\n",
    "print(\"Best hyperparameters saved to 'best_hyperparameters.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 222.3247 - accuracy: 0.5426\n",
      "Epoch 2/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 53.9013 - accuracy: 0.6012\n",
      "Epoch 3/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 21.1514 - accuracy: 0.6544\n",
      "Epoch 4/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 11.5382 - accuracy: 0.6844\n",
      "Epoch 5/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 6.3933 - accuracy: 0.7096\n",
      "Epoch 6/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 3.8130 - accuracy: 0.7241\n",
      "Epoch 7/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 2.5961 - accuracy: 0.7240\n",
      "Epoch 8/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 1.4100 - accuracy: 0.7441\n",
      "Epoch 9/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.9314 - accuracy: 0.7542\n",
      "Epoch 10/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.6570 - accuracy: 0.7767\n",
      "Epoch 11/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.5416 - accuracy: 0.7987\n",
      "Epoch 12/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.4289 - accuracy: 0.8266\n",
      "Epoch 13/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3970 - accuracy: 0.8339\n",
      "Epoch 14/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.4077 - accuracy: 0.8291\n",
      "Epoch 15/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.4068 - accuracy: 0.8316\n",
      "Epoch 16/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3911 - accuracy: 0.8370\n",
      "Epoch 17/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3897 - accuracy: 0.8383\n",
      "Epoch 18/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3942 - accuracy: 0.8353\n",
      "Epoch 19/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3884 - accuracy: 0.8380\n",
      "Epoch 20/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3858 - accuracy: 0.8388\n",
      "Epoch 21/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3801 - accuracy: 0.8416\n",
      "Epoch 22/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3845 - accuracy: 0.8397\n",
      "Epoch 23/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3779 - accuracy: 0.8435\n",
      "Epoch 24/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3812 - accuracy: 0.8427\n",
      "Epoch 25/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3740 - accuracy: 0.8456\n",
      "Epoch 26/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3731 - accuracy: 0.8450\n",
      "Epoch 27/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3808 - accuracy: 0.8420\n",
      "Epoch 28/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3736 - accuracy: 0.8455\n",
      "Epoch 29/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3750 - accuracy: 0.8444\n",
      "Epoch 30/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3717 - accuracy: 0.8464\n",
      "Epoch 31/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3716 - accuracy: 0.8465\n",
      "Epoch 32/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3699 - accuracy: 0.8474\n",
      "Epoch 33/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3713 - accuracy: 0.8462\n",
      "Epoch 34/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3697 - accuracy: 0.8478\n",
      "Epoch 35/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3763 - accuracy: 0.8441\n",
      "Epoch 36/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3722 - accuracy: 0.8459\n",
      "Epoch 37/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8470\n",
      "Epoch 38/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3756 - accuracy: 0.8450\n",
      "Epoch 39/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3699 - accuracy: 0.8478\n",
      "Epoch 40/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3694 - accuracy: 0.8476\n",
      "Epoch 41/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3710 - accuracy: 0.8471\n",
      "Epoch 42/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3700 - accuracy: 0.8480\n",
      "Epoch 43/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3631 - accuracy: 0.8519\n",
      "Epoch 44/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3783 - accuracy: 0.8435\n",
      "Epoch 45/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3689 - accuracy: 0.8485\n",
      "Epoch 46/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3701 - accuracy: 0.8477\n",
      "Epoch 47/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3899 - accuracy: 0.8385\n",
      "Epoch 48/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3700 - accuracy: 0.8483\n",
      "Epoch 49/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8469\n",
      "Epoch 50/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3716 - accuracy: 0.8465\n",
      "Epoch 51/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3767 - accuracy: 0.8440\n",
      "Epoch 52/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3814 - accuracy: 0.8421\n",
      "Epoch 53/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8457\n",
      "Epoch 54/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3717 - accuracy: 0.8469\n",
      "Epoch 55/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3700 - accuracy: 0.8479\n",
      "Epoch 56/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3824 - accuracy: 0.8418\n",
      "Epoch 57/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.4088 - accuracy: 0.8321\n",
      "Epoch 58/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3798 - accuracy: 0.8437\n",
      "Epoch 59/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3898 - accuracy: 0.8401\n",
      "Epoch 60/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3747 - accuracy: 0.8466\n",
      "Epoch 61/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3710 - accuracy: 0.8478\n",
      "Epoch 62/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3898 - accuracy: 0.8391\n",
      "Epoch 63/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3691 - accuracy: 0.8490\n",
      "Epoch 64/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3703 - accuracy: 0.8483\n",
      "Epoch 65/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3723 - accuracy: 0.8470\n",
      "Epoch 66/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3750 - accuracy: 0.8463\n",
      "Epoch 67/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3764 - accuracy: 0.8460\n",
      "Epoch 68/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8457\n",
      "Epoch 69/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3677 - accuracy: 0.8493\n",
      "Epoch 70/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3721 - accuracy: 0.8470\n",
      "Epoch 71/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3864 - accuracy: 0.8406\n",
      "Epoch 72/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3748 - accuracy: 0.8471\n",
      "Epoch 73/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3869 - accuracy: 0.8417\n",
      "Epoch 74/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3700 - accuracy: 0.8483\n",
      "Epoch 75/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3694 - accuracy: 0.8488\n",
      "Epoch 76/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8459\n",
      "Epoch 77/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3614 - accuracy: 0.8518\n",
      "Epoch 78/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3635 - accuracy: 0.8514\n",
      "Epoch 79/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3653 - accuracy: 0.8505\n",
      "Epoch 80/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3689 - accuracy: 0.8489\n",
      "Epoch 81/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3720 - accuracy: 0.8476\n",
      "Epoch 82/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3740 - accuracy: 0.8466\n",
      "Epoch 83/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3718 - accuracy: 0.8477\n",
      "Epoch 84/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3657 - accuracy: 0.8506\n",
      "Epoch 85/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3651 - accuracy: 0.8511\n",
      "Epoch 86/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3698 - accuracy: 0.8484\n",
      "Epoch 87/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3733 - accuracy: 0.8469\n",
      "Epoch 88/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3647 - accuracy: 0.8505\n",
      "Epoch 89/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3677 - accuracy: 0.8491\n",
      "Epoch 90/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3806 - accuracy: 0.8431\n",
      "Epoch 91/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3755 - accuracy: 0.8468\n",
      "Epoch 92/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3677 - accuracy: 0.8485\n",
      "Epoch 93/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3734 - accuracy: 0.8471\n",
      "Epoch 94/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3632 - accuracy: 0.8520\n",
      "Epoch 95/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3665 - accuracy: 0.8502\n",
      "Epoch 96/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3794 - accuracy: 0.8459\n",
      "Epoch 97/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3640 - accuracy: 0.8514\n",
      "Epoch 98/200\n",
      "1107/1107 [==============================] - 3s 2ms/step - loss: 0.3730 - accuracy: 0.8469\n",
      "Epoch 99/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3677 - accuracy: 0.8489\n",
      "Epoch 100/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3673 - accuracy: 0.8496\n",
      "Epoch 101/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3640 - accuracy: 0.8514\n",
      "Epoch 102/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3646 - accuracy: 0.8508\n",
      "Epoch 103/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3612 - accuracy: 0.8526\n",
      "Epoch 104/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3610 - accuracy: 0.8529\n",
      "Epoch 105/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3716 - accuracy: 0.8475\n",
      "Epoch 106/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3697 - accuracy: 0.8492\n",
      "Epoch 107/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3625 - accuracy: 0.8526\n",
      "Epoch 108/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3671 - accuracy: 0.8497\n",
      "Epoch 109/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3636 - accuracy: 0.8518\n",
      "Epoch 110/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3634 - accuracy: 0.8518\n",
      "Epoch 111/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3599 - accuracy: 0.8536\n",
      "Epoch 112/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3633 - accuracy: 0.8525\n",
      "Epoch 113/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8531\n",
      "Epoch 114/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3703 - accuracy: 0.8485\n",
      "Epoch 115/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3585 - accuracy: 0.8532\n",
      "Epoch 116/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3635 - accuracy: 0.8517\n",
      "Epoch 117/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3689 - accuracy: 0.8494\n",
      "Epoch 118/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3649 - accuracy: 0.8509\n",
      "Epoch 119/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3629 - accuracy: 0.8518\n",
      "Epoch 120/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3703 - accuracy: 0.8485\n",
      "Epoch 121/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8538\n",
      "Epoch 122/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8533\n",
      "Epoch 123/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3606 - accuracy: 0.8526\n",
      "Epoch 124/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3598 - accuracy: 0.8530\n",
      "Epoch 125/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3616 - accuracy: 0.8525\n",
      "Epoch 126/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3684 - accuracy: 0.8493\n",
      "Epoch 127/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3584 - accuracy: 0.8541\n",
      "Epoch 128/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3605 - accuracy: 0.8532\n",
      "Epoch 129/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3559 - accuracy: 0.8554\n",
      "Epoch 130/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3616 - accuracy: 0.8532\n",
      "Epoch 131/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3593 - accuracy: 0.8535\n",
      "Epoch 132/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8528\n",
      "Epoch 133/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3560 - accuracy: 0.8548\n",
      "Epoch 134/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3604 - accuracy: 0.8536\n",
      "Epoch 135/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3593 - accuracy: 0.8537\n",
      "Epoch 136/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3618 - accuracy: 0.8524\n",
      "Epoch 137/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3640 - accuracy: 0.8518\n",
      "Epoch 138/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3607 - accuracy: 0.8539\n",
      "Epoch 139/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3622 - accuracy: 0.8525\n",
      "Epoch 140/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3628 - accuracy: 0.8522\n",
      "Epoch 141/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3581 - accuracy: 0.8541\n",
      "Epoch 142/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8528\n",
      "Epoch 143/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3583 - accuracy: 0.8545\n",
      "Epoch 144/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3578 - accuracy: 0.8548\n",
      "Epoch 145/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3599 - accuracy: 0.8539\n",
      "Epoch 146/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8538\n",
      "Epoch 147/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3673 - accuracy: 0.8507\n",
      "Epoch 148/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3572 - accuracy: 0.8544\n",
      "Epoch 149/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3618 - accuracy: 0.8527\n",
      "Epoch 150/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3581 - accuracy: 0.8544\n",
      "Epoch 151/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3582 - accuracy: 0.8546\n",
      "Epoch 152/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3614 - accuracy: 0.8528\n",
      "Epoch 153/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3604 - accuracy: 0.8534\n",
      "Epoch 154/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3569 - accuracy: 0.8551\n",
      "Epoch 155/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3624 - accuracy: 0.8529\n",
      "Epoch 156/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8527\n",
      "Epoch 157/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3562 - accuracy: 0.8552\n",
      "Epoch 158/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3598 - accuracy: 0.8541\n",
      "Epoch 159/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3574 - accuracy: 0.8545\n",
      "Epoch 160/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3672 - accuracy: 0.8507\n",
      "Epoch 161/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3574 - accuracy: 0.8552\n",
      "Epoch 162/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3609 - accuracy: 0.8536\n",
      "Epoch 163/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3567 - accuracy: 0.8554\n",
      "Epoch 164/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3675 - accuracy: 0.8501\n",
      "Epoch 165/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3602 - accuracy: 0.8535\n",
      "Epoch 166/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3559 - accuracy: 0.8558\n",
      "Epoch 167/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3603 - accuracy: 0.8532\n",
      "Epoch 168/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3566 - accuracy: 0.8555\n",
      "Epoch 169/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3552 - accuracy: 0.8559\n",
      "Epoch 170/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3652 - accuracy: 0.8524\n",
      "Epoch 171/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8558\n",
      "Epoch 172/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3559 - accuracy: 0.8554\n",
      "Epoch 173/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3557 - accuracy: 0.8557\n",
      "Epoch 174/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3596 - accuracy: 0.8539\n",
      "Epoch 175/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8533\n",
      "Epoch 176/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3535 - accuracy: 0.8566\n",
      "Epoch 177/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8564\n",
      "Epoch 178/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3570 - accuracy: 0.8556\n",
      "Epoch 179/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3573 - accuracy: 0.8551\n",
      "Epoch 180/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8560\n",
      "Epoch 181/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8559\n",
      "Epoch 182/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3558 - accuracy: 0.8556\n",
      "Epoch 183/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3549 - accuracy: 0.8558\n",
      "Epoch 184/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3551 - accuracy: 0.8559\n",
      "Epoch 185/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8561\n",
      "Epoch 186/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8553\n",
      "Epoch 187/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8566\n",
      "Epoch 188/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3551 - accuracy: 0.8562\n",
      "Epoch 189/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3553 - accuracy: 0.8559\n",
      "Epoch 190/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8571\n",
      "Epoch 191/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3559 - accuracy: 0.8555\n",
      "Epoch 192/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3546 - accuracy: 0.8564\n",
      "Epoch 193/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3552 - accuracy: 0.8557\n",
      "Epoch 194/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8558\n",
      "Epoch 195/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3523 - accuracy: 0.8574\n",
      "Epoch 196/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3562 - accuracy: 0.8552\n",
      "Epoch 197/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3556 - accuracy: 0.8558\n",
      "Epoch 198/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3571 - accuracy: 0.8553\n",
      "Epoch 199/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3538 - accuracy: 0.8568\n",
      "Epoch 200/200\n",
      "1107/1107 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choeseung-u/programming/econometrics/econometrics/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Class Weight\n",
    "# class_weights = compute_class_weight('balanced', classes=[0,1], y=y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "# Load best hyperparameters\n",
    "with open('best_hyperparameters.json') as f:\n",
    "    best_hps = json.load(f)\n",
    "\n",
    "model_path = 'final_trained_model.h5'\n",
    "if(os.path.exists(model_path)):\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=best_hps['units'], activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(best_hps['dropout']))\n",
    "    model.add(Dense(units=best_hps['units2'], activation='relu'))\n",
    "    model.add(Dropout(best_hps['dropout2']))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=200, batch_size=256\n",
    "                    # , class_weight=class_weight_dict\n",
    "                    )  # Adjust epochs and batch_size as needed\n",
    "\n",
    "# Save the final trained model\n",
    "model.save('final_trained_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1772/1772 - 1s - loss: 0.3464 - accuracy: 0.8610 - 925ms/epoch - 522us/step\n",
      "Test accuracy: 0.8609944581985474\n",
      "1772/1772 [==============================] - 1s 449us/step\n",
      "Confusion Matrix:\n",
      " [[23653  4610]\n",
      " [ 3268 25143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.84      0.86     28263\n",
      "         1.0       0.85      0.88      0.86     28411\n",
      "\n",
      "    accuracy                           0.86     56674\n",
      "   macro avg       0.86      0.86      0.86     56674\n",
      "weighted avg       0.86      0.86      0.86     56674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plotting the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Predictions for confusion matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int).reshape(-1)  # Adjust this line if not a binary classification\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
