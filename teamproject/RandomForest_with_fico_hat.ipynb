{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('lendingclub_train.dta')\n",
    "# df.head()\n",
    "# df.describe()\n",
    "columns_to_drop = [\n",
    "    \"index\",\n",
    "    \"depvar\",\n",
    "    \"total_acc\", \n",
    "    \"out_prncp\", \n",
    "    \"out_prncp_inv\", \n",
    "    \"total_pymnt\", \n",
    "    \"total_pymnt_inv\", \n",
    "    \"total_rec_prncp\", \n",
    "    \"total_rec_int\", \n",
    "    \"total_rec_late_fee\", \n",
    "    \"recoveries\", \n",
    "    \"collection_recovery_fee\",\n",
    "    \"last_pymnt_amnt\", \n",
    "    \"last_fico_range_high\", \n",
    "    \"last_fico_range_low\", \n",
    "    \"tot_coll_amt\", \n",
    "    \"tot_cur_bal\", \n",
    "    \"initial_list_status1\", \n",
    "    \"initial_list_status2\", \n",
    "    \"elapsed_t\",\n",
    "    \"purpose1\",\n",
    "    \"addr_state1\",\n",
    "    \"elapsed_t\",\n",
    "    \"debt_settlement_flag1\",\n",
    "    \"term1\",\n",
    "    \"mths_since_last_delinq1\",\n",
    "    \"mths_since_last_major_derog1\",\n",
    "    \"mths_since_last_record1\",\n",
    "    \"mths_since_rcnt_il1\",\n",
    "    \"mths_since_recent_bc1\",\n",
    "    \"mths_since_recent_bc_dlq1\",\n",
    "    \"mths_since_recent_inq1\",\n",
    "    \"mths_since_recent_revol_delinq1\"\n",
    "]\n",
    "\n",
    "issue_d_count = 1\n",
    "while(issue_d_count <= 118):\n",
    "    word_tmp = \"issue_d\" + str(issue_d_count)\n",
    "    columns_to_drop.append(word_tmp)\n",
    "    issue_d_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "필요없으면 건너뛰어도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df['depvar'] == 0]\n",
    "df_minority = df[df['depvar'] == 1]\n",
    "\n",
    "# Count number of instances in the minority class\n",
    "minority_count = len(df_minority)\n",
    "\n",
    "# Undersample the majority class\n",
    "df_majority_undersampled = df_majority.sample(n=minority_count, random_state=42)\n",
    "\n",
    "# Combine minority class with the undersampled majority class\n",
    "df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_undersampled = df_undersampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# Now split into features and target, and then into training and testing sets\n",
    "y = df_undersampled['depvar']\n",
    "X_original = df_undersampled\n",
    "X = df_undersampled.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fico hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "rf_fico_high = joblib.load('random_forest_fico_high.joblib')\n",
    "rf_fico_low = joblib.load('random_forest_fico_low.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/choeseung-u/programming/econometrics/teamproject/RandomForest_with_fico_hat.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choeseung-u/programming/econometrics/teamproject/RandomForest_with_fico_hat.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fico_high_threshold \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choeseung-u/programming/econometrics/teamproject/RandomForest_with_fico_hat.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fico_low_threshold \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/choeseung-u/programming/econometrics/teamproject/RandomForest_with_fico_hat.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m last_fico_high_hat\u001b[39m=\u001b[39m rf_fico_high\u001b[39m.\u001b[39;49mpredict_proba(X)[:,\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choeseung-u/programming/econometrics/teamproject/RandomForest_with_fico_hat.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m last_fico_high_onehot \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame((last_fico_high_hat \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m fico_high_threshold)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choeseung-u/programming/econometrics/teamproject/RandomForest_with_fico_hat.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m last_fico_high_onehot\u001b[39m.\u001b[39mcolumns\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:876\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    871\u001b[0m all_proba \u001b[39m=\u001b[39m [\n\u001b[1;32m    872\u001b[0m     np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    873\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m    874\u001b[0m ]\n\u001b[1;32m    875\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 876\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[1;32m    877\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict_proba, X, all_proba, lock)\n\u001b[1;32m    878\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mfor\u001b[39;00m proba \u001b[39min\u001b[39;00m all_proba:\n\u001b[1;32m    882\u001b[0m     proba \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:647\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[1;32m    641\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[39m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[39m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     prediction \u001b[39m=\u001b[39m predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[39mwith\u001b[39;00m lock:\n\u001b[1;32m    649\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/programming/econometrics/econometrics/lib/python3.11/site-packages/sklearn/tree/_classes.py:993\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    991\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    992\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m--> 993\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    996\u001b[0m     proba \u001b[39m=\u001b[39m proba[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fico_high_threshold = 0.5\n",
    "fico_low_threshold = 0.5\n",
    "last_fico_high_hat= rf_fico_high.predict_proba(X)[:,1]\n",
    "last_fico_high_onehot = pd.DataFrame((last_fico_high_hat >= fico_high_threshold).astype(int))\n",
    "last_fico_high_onehot.columns= ['']\n",
    "last_fico_high_onehot = last_fico_high_onehot.to_numpy()\n",
    "# last_fico_onehot = pd.DataFrame(last_fico_high_hat[])\n",
    "# last_fico_high_hat= rf_fico_high.predict(X_original)\n",
    "\n",
    "last_fico_low_hat= rf_fico_low.predict_proba(X)[:,1]\n",
    "last_fico_low_onehot = pd.DataFrame((last_fico_low_hat >= fico_low_threshold).astype(int))\n",
    "last_fico_low_onehot.columns= ['']\n",
    "last_fico_low_onehot = last_fico_low_onehot.to_numpy()\n",
    "\n",
    "# X['last_fico_high_hat'] = last_fico_high_onehot\n",
    "# X['last_fico_low_hat'] = last_fico_low_onehot\n",
    "\n",
    "\n",
    "X['last_fico_high_hat'] = last_fico_high_hat\n",
    "X['last_fico_low_hat'] = last_fico_low_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 874335 entries, 0 to 874334\n",
      "Columns: 188 entries, loan_amnt to mths_since_recent_revol_delinq11\n",
      "dtypes: float64(6), int16(5), int32(6), int8(171)\n",
      "memory usage: 211.0 MB\n"
     ]
    }
   ],
   "source": [
    "# y = df['depvar']\n",
    "# X = df.drop(columns=columns_to_drop)\n",
    "# X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X and y are your features and target variable\n",
    "# X = your_data_features\n",
    "# y = your_data_target\n",
    "\n",
    "# Splitting the data into training, validation and testing sets\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [5, 10]  ###############################<==이부분을 각자 하나씩 맡으면 됩니다!!\n",
    "}\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy: \", val_accuracy)\n",
    "print(\"Validation Classification Report: \\n\", val_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=300,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=300,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=300,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Random Forest Classifier\n",
    "# rf = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split'], random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=20, min_samples_split=10, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659932244062533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.66      0.66     28263\n",
      "         1.0       0.66      0.66      0.66     28411\n",
      "\n",
      "    accuracy                           0.66     56674\n",
      "   macro avg       0.66      0.66      0.66     56674\n",
      "weighted avg       0.66      0.66      0.66     56674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31595816, 0.68404184],\n",
       "       [0.37685502, 0.62314498],\n",
       "       [0.37579307, 0.62420693],\n",
       "       ...,\n",
       "       [0.72587175, 0.27412825],\n",
       "       [0.7929639 , 0.2070361 ],\n",
       "       [0.65435306, 0.34564694]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = rf.predict_proba(X_test)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_final.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# save\n",
    "joblib.dump(rf, \"random_forest_final.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = rf.predict_proba(X_val)\n",
    "y_val_pred1 = y_val_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7145156396992403"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y_val,y_val_pred1)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column drop 안된 원래 애들 생성\n",
    "X_original_train, X_original_temp, y_train, y_temp = train_test_split(X_original, y, test_size=0.4, random_state=42)\n",
    "X_original_val, X_original_test, y_val, y_test = train_test_split(X_original_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['tn_gain'] = X_val_thres['funded_amnt'] * X_val_thres['int_rate'] * 36\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['tp_gain'] = X_val_thres['funded_amnt'] * gov_bond_rate\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['fn_loss'] = X_val_thres['funded_amnt'] * (1+gov_bond_rate) - X_val_thres['total_rec_prncp']\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['fp_loss'] = X_val_thres['funded_amnt'] * (X_val_thres['int_rate'] - gov_bond_rate)\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['rf_pred_proba'] = rf.predict_proba(X_val)[:,1]\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['rf_pred_onehot'] = X_val_thres['rf_pred_proba'].apply(lambda row: 1 if row > threshold else 0)\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['predict_result'] = X_val_thres.apply(lambda row: 'tp' if ((row['depvar'] == row['rf_pred_onehot']) and (row['rf_pred_onehot'] == 1))\n",
      "/var/folders/lx/3vyc9qlj1cqg5xytpq0yk4680000gn/T/ipykernel_10702/888816392.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_thres['gain_or_loss'] = X_val_thres.apply(lambda row: row['tn_gain'] if (row['predict_result'] == 'tn')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>gain_or_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.616925e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.616925e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.616925e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.616925e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.616925e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.96</td>\n",
       "      <td>1.447171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.447171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.447171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.447171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.447171e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold  gain_or_loss\n",
       "0         0.00 -1.616925e+07\n",
       "1         0.01 -1.616925e+07\n",
       "2         0.02 -1.616925e+07\n",
       "3         0.03 -1.616925e+07\n",
       "4         0.04 -1.616925e+07\n",
       "..         ...           ...\n",
       "96        0.96  1.447171e+09\n",
       "97        0.97  1.447171e+09\n",
       "98        0.98  1.447171e+09\n",
       "99        0.99  1.447171e+09\n",
       "100       1.00  1.447171e+09\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gain domain(금액 모두 돌려받고 추가로 이자소득이 나옴)\n",
    "# = TN*펀딩액*이자율 + TP*펀딩액*미국국채이자율\n",
    "# Loss domain(이자소득을 따지기 이전에 원금이 안돌아옴)\n",
    "# = FN * (펀딩금액 * (1+국채이자율) - 부도전까지갚은금액 - 부도전까지갚은이자) + FP*펀딩액*(랜딩클럽이자율 - 미국국채이자율)\n",
    "\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "gov_bond_rate = 0.04\n",
    "\n",
    "\n",
    "X_val_thres = X_original_val\n",
    "X_val_thres['tn_gain'] = X_val_thres['funded_amnt'] * X_val_thres['int_rate'] * 36\n",
    "X_val_thres['tp_gain'] = X_val_thres['funded_amnt'] * gov_bond_rate\n",
    "X_val_thres['fn_loss'] = X_val_thres['funded_amnt'] * (1+gov_bond_rate) - X_val_thres['total_rec_prncp'] \n",
    "X_val_thres['fp_loss'] = X_val_thres['funded_amnt'] * (X_val_thres['int_rate'] - gov_bond_rate)\n",
    "X_val_thres['rf_pred_proba'] = rf.predict_proba(X_val)[:,1]\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['threshold', 'gain_or_loss'])\n",
    "\n",
    "for threshold in thresholds:\n",
    "\n",
    "    # X_val_thres['rf_pred_proba']\n",
    "    X_val_thres['rf_pred_onehot'] = X_val_thres['rf_pred_proba'].apply(lambda row: 1 if row > threshold else 0)\n",
    "\n",
    "    X_val_thres['predict_result'] = X_val_thres.apply(lambda row: 'tp' if ((row['depvar'] == row['rf_pred_onehot']) and (row['rf_pred_onehot'] == 1))\n",
    "                                            else 'tn' if ((row['depvar'] == row['rf_pred_onehot']) and (row['rf_pred_onehot'] == 0))\n",
    "                                            else 'fp' if (row['rf_pred_onehot'] == 1) \n",
    "                                            else 'fn', axis=1)\n",
    "\n",
    "    X_val_thres['gain_or_loss'] = X_val_thres.apply(lambda row: row['tn_gain'] if (row['predict_result'] == 'tn')\n",
    "                                                    else row['tp_gain'] if (row['predict_result'] == 'tp')\n",
    "                                                    else row['fn_loss']*-1 if (row['predict_result'] == 'fn')\n",
    "                                                    else row['fp_loss']*-1, axis=1)\n",
    "\n",
    "    X_val_thres['gain_or_loss'].sum()\n",
    "\n",
    "    metrics_df.loc[len(metrics_df.index)] = [threshold, X_val_thres['gain_or_loss'].sum()]\n",
    "\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8300000000000001\n",
      "1447196455.4699998\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = metrics_df.threshold[metrics_df.gain_or_loss.idxmax()]\n",
    "print(optimal_threshold)\n",
    "print(metrics_df.gain_or_loss.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
